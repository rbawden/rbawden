<!DOCTYPE html>
<html lang="en">
<head>
    <title>DiaBLa - description and statistics</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">    
    <link rel="shortcut icon" href="favicon.ico">  
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <!-- FontAwesome JS -->
    <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
    <!-- Plugins CSS -->    
    <link rel="stylesheet" href="assets/plugins/prism/prism.css">
    <link rel="stylesheet" href="assets/plugins/lightbox/dist/ekko-lightbox.css">
    <link rel="stylesheet" href="assets/plugins/elegant_font/css/style.css">

    <!-- Theme CSS -->
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
    
</head> 

<body class="body-pink">
    <div class="page-wrapper">
        <!-- ******Header****** -->
        <header id="header" class="header">
            <div class="container">
                <div class="branding">
                    <h1 class="logo">
                        <a href="index.html">
                            <i class="far fa-comments" aria-hidden="true"></i>
                            <span class="text-highlight">Dia</span><span class="text-bold">BLa</span>
                        </a>
                    </h1>
                </div><!--//branding-->
                <ol class="breadcrumb">
                    <li class="breadcrumb-item"><a href="index.html">Home</a></li>
                    <li class="breadcrumb-item active">Description</li>
                </ol>
            </div><!--//container-->
        </header><!--//header-->
        <div class="doc-wrapper">
            <div class="container">
                <div id="doc-header" class="doc-header text-center">
                    <h1 class="doc-title"><i class="bigicon fas fa-file-alt"></i></span> Corpus description</h1>
		<div class="meta"><i class="far fa-clock"></i>
		  Last updated: 3rd December 2020</div>
                </div><!--//doc-header-->
		<div class="doc-body row" >
		<div class="doc-content col-md-9 col-12 order-1">
		<div class="content-inner">

		  <section id="description" class="doc-section">
		  <h2 class="section-title"><a id="description"></a>Description</h2>

		  <p>The dataset is an English-French dataset for the evaluation of Machine
		  Translation (MT) for informal, written bilingual dialogue.</p>

		  <p>The dataset
		  contains 144 spontaneous dialogues (5,700+ sentences) between native English
		  and French speakers, mediated by <a href="#mt-models">one of two neural MT systems</a>
		  in a range of <a href="#role-play">role-play settings</a>.
		  See below for some <a href="#stats">basic statistics</a>.</p>

		  <p>The dialogues are accompanied by fine-grained sentence-level
		  judgments of MT quality, produced by the dialogue participants themselves,
		  as well as by manually normalised versions and reference translations produced <span class="font-italic">a
		  posteriori</span>. See <a href="#eval">here</a> for information about evaluation.</p>

		  <p>The motivation for the corpus is two-fold: to provide</p>
		  <ol>
		    <li>a unique resource for evaluating MT models, </li>
		    <li>a corpus for the analysis of MT-mediated
		  communication</li>
		</ol>

		<h3 class="section-subtitle"><a id="mt-models"></a>MT-mediated dialogue</h3>

		<p>Participants are either English or French native speakers and they interact through a
		<a href="https://github.com/rbawden/diabla-chat-interface">dedicated online
		chat tool. </a> They write in their native language and their utterances are automatically translated into
		the other language using one of two MT model types: (i) a baseline RNN NMT model and (ii) a lightly contextual
		RNN NMT model that takes into account the preceding sentence.</p>

		<p>Each participant therefore sees the entire dialogue in their native language (i.e. they only see the
		machine-translated versions of their partner's original utterances.

		An example of the interface and the same dialogue as seen by both users:</p>
		<img style="width:100%" src="img/example-dialogue.png">

		<p>The interface is constructed on top of <a href="https://github.com/miguelgrinberg/Flask-SocketIO-Chat">this
		simple chat Flask example</a>, and the modified code
		can be found online <a href="https://github.com/rbawden/diabla-chat-interface">here</a>.</p>

		<p class="font-weight-bold">Some more information about the MT models used:</p>

		<p>Full technical details on the training of the models can be found in the
		<a href="https://hal.inria.fr/hal-03021633/document">paper</a>. Both models are
		RNN-based encoder-decoder models with attention, trained on OpenSubtitles2016 data
		<a href="http://opus.nlpl.eu/OpenSubtitles-v2016.php">(Lison and Tiedemann, 2016)</a>.</p> 
		<ul>
		  <li> Baseline model: the model is trained on individual sentences and translates a text
		  sentence by sentence</li>
		  <li> Contextual model (2-to-2): the model is trained to use one previous sentence of context. It does this using
		  a simple concatenation method, 2-to-2 (<a href="https://www.aclweb.org/anthology/W17-4811/">Tiedemann and Scherrer, 2017</a>;
		  <a href="https://www.aclweb.org/anthology/N18-1118/">Bawden et al., 2018</a>), which involves:
		  <ul>
		    <li>
		    Prefixing each sentence with its previous sentence, separated by a special sentence separator token
		    and training the model on this example to predict the translation of the two sentences together (as if
		    they were a single example). N.B. the separator token is also translated.
		    </li>
		    <li>
		    At test time, prefixing each sentence with the previous sentence, translating them both and in a post-processing
		    step, just taking the translation of the current sentence by removing everything up to and including the translated
		    separator token.
		    </li>
		  </ul>
		</li>
		</ul>

		<h3 class="section-subtitle"><a id="role-play"></a>Role-play scenarios</h3>

		Why role-play scenarios?
		<ul>
		  <li>Help to ground the dialogue in a situation, making it easier for participants to find topics to talk about</li>
		  <li>Encourage the participants to be imaginative and to be immersed in the scenario (avoiding salutations and pleasantries)</li>
		  <li>Provide anonymity for the participants, making it possible to distribute the corpus freely</li>
		  <li>Constrain the scenarios to careful chosen ones, encouraging diverse scenarios but within limits</li>
		</ul>

		<p>There are a total of 12 scenarios (with associated roles for each participant). The scenarios were used an equal number
		of times for each MT model type and the roles were assigned randomly at the beginning of the dialogue. The
		scenario and roles were provided in either French or English depending on the language of the speaker.</p>

		<ol>
		<li> You are both lost in a forest.<br>
		  Roles: N/A
		</li>
		<li>You are chefs preparing a meal. <br>
		Role 1: You are the head chef and you are talking to your subordinate. <br>
		Role 2: You are the subordinate chef and you are talking to the head chef.
		</li>
		<li>
		You are in a classroom. <br>
		Role 1: You are the teacher and you are talking to a student. <br>
		Role 2: You are the student and you are talking to your teacher.
		<li>
		You are feeding the ducks by the pond. <br>
		Roles: N/A
		</li>
		<li>
		You are both organising a party. <br>
		Role 1: It’s your party. <br>
		Role 2: It’s their party.
		</li>
		<li>
		You are both stuck in a lift at work. <br>
		Role 1: You are an employee and you are with your boss. <br>
		Role 2: You are the boss and are with an employee.
		</li>
		<li>
		You are in a retirement home. <br>
		Role 1: You are visiting and talking to an old friend. <br>
		Role 2: You are a resident and you are talking with an old friend who is visiting you.
		</li>
		<li>
		You are in a bar. <br>
		Role 1: You are the bartender and talking to a customer. <br>
		Role 2: You are a customer and are talking to the bartender.
		</li>
		<li>
		You are in an aeroplane. <br>
		Role 1: You are scared and are speaking to the person sitting next to you. <br>
		Role 2: You are speaking to the person next to you, who is scared.
		</li>
		<li>
		You are at home in the evening. <br>
		Role 1: You are telling your spouse about the awful day you had. <br>
		Role 2: You are listening to your spouse telling you about the awful day they had.
		</li>
		<li>
		You are in a psychiatrist’s consulting room. <br>
		Role 1: You are the psychiatrist and are with your patient. <br>
		Role 2: You are a patient and you are talking to your psychiatrist.
		</li>
		<li>
		You are on holiday by the pool. <br>
		Role 1: You are trying to relax and the other person wants to do something else. <br>
		Role 2: You want to do something else and the other person is trying to relax.
		</li>
	      </ol>

		<h3 class="section-subtitle"><a id="eval"></a>Evaluation</h3>


	      The dataset can be used for evaluation in different ways:
	      <ul>
		<li>As a standard parallel test set - <a href="#human-refs">human references translations</a> were produced
		<span class="font-italic">a posteriori</span> for all sentences</li>
		<li>The users provided <a href="#user-eval">real-time feedback of the machine translation models</a> used
		and this can be used to directly evaluate those models</li>
		<li>The protocol can be reused with new MT models (also with new
		participants, languages and scenarios)</li>
	      </ul>

	      <h4><a id="human-refs"></a>Human translations</h4>
	      <p>Human translations of all sentences were produced <span class="font-italic">a posteriori</span>
	      by native speakers of each target
	      language (English and French). They were then post-edited and verified by a bilingual speaker.
	      Particular attention was paid to the naturalness of the translations, avoiding overly literal or
	      stilted translations. The translations respected source sentence boundaries, but the translation
	      could contain several sentences.</p>

	      <h4><a id="user-eval"></a>Real-time human evaluations</h4>

	      <p>The users only see the machine-translated versions of their partner's utterances (they see the entire
	      dialogue in their native language). However, they evaluate those utterances according
	      to their knowledge of the language and what seems coherent with respect to the dialogue.</p>

	      <p>Three types of evaluations:</p>

	      <ol>
		<li>Sentence-level coarse-grained quality score: green happy face (perfect), orange neutral
		face (medium) and red sad face (poor)</li>
		<li>In the case of a non-perfect annotation, they are then invited to indicate which types
		of errors appeared (several allowed): grammatical, meaning, word choice, style, coherence, other. See below for an
		example.</li>
		<li>Final evaluation at the end of the dialogue, concerning the quality of the dialogue, any problems
		they encountered, general impressions.</li>
	      </ol>

	      <img style="width:20%; min-width:300px;" src="img/img-eval-problems.png">

	      <p>The results of the evaluation showed that there were some perceptible differences in the two types
	      of model and between the language directions:</p>

	      <p>The coarse-grained results (percentage of sentences with each rating) gave the following:</p>
	      <img style="width:500px;" src="img/coarse-results.png">
	      <p>The evaluations are very similar for both model types. For English-to-French, there is a slight preference
	      for the contextual model (+4.3% of 'perfect' sentences). For French-to-English, the percentages are much similar,
	      with -0.96% 'perfect' sentences for the contextual model. In both cases, the percentage of 'poor' sentences
	      is decreased for the contextual model.</p>

	      <p>And a breakdown of the different errors for each model (percentage of sentences containing a specific error type)
	      was as follows:</p>
	      <img style="width:500px;" src="img/fine-results.png">

	      <p>There are far more errors noted for English-to-French, the most prevalent one
	      being 'word choice'. The contextual 2-to-2 model produces slightly more word choice
	      errors than the baseline. However, the percentage of sentences with coherence errors and with style errors is reduced when using context.</p>

	      <p>More details can be found in the <a href="https://hal.inria.fr/hal-03021633">paper</a>.</p>
	      
	      </section>
	      <section id="dashboards" class="doc-section">
	      
	      <h2 class="section-title"><a id="stats"></a>Basic Statistics</h2>

	    <div class="section-block">
	      <h3 class="section-subtitle"><a id="corpus-stats"></a>Textual statistics</h3>
	      

		  <p>Some basic statistics concerning the corpus collected:</p>
		  <table class="table table-hover table-sm ">
		    <thead class="thead-light">
		      <tr>
			<th>Language direction</th><th>En2Fr</th><th>Fr2En</th><th>All</th>
		      </tr>
		      </thead>
		    <tbody>
		      <tr>
			<th colspan="4" class="text-center">#Turns</th>
		      </tr>
		      <tr>
			<th scope="row">Total</th><td>1,067</td><td>1,089</td><td>2156</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per dialogue</th><td>7.4</td><td>7.6</td><td>15.0</td>
		      </tr>
		      <tr>
			<th colspan="4" class="text-center">#Sentences</th>
		      </tr>
		      <tr>
			<th scope="row">Total</th><td>2,865</td><td>2,883</td><td>5,748</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per dialogue</th><td>19.9</td><td>20.0</td><td>39.9</td>
		      </tr>
		      <tr>	
			<th scope="row">Min. / Max. per dialogue</th><td>5 / 42</td><td>5 / 60</td><td>10 / 102</td>
		      </tr>
		      <tr>	
			<th scope="row">Mean per turn</th><td>2.7</td><td>2.6</td><td>2.7</td>
		      </tr>
		      <tr>
			<th scope="row">Min. / Max. per turn</th><td>1 / 9</td><td>1 / 10</td><td>1 / 10</td>
		      </tr>
		      <tr>
			<th colspan="4" class="text-center">#Tokens (original messages)</th>
		      </tr>
		      <tr>
			<th scope="row">Total</th><td>27,817</td><td>29,058</td><td>56,875</td>
		      </tr>
		      <tr>
			<th scope="row">Total unique</th><td>3,588</td><td>4,244</td><td>-</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per dialogue</th><td>193.2</td><td>201.8</td><td>395.0</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per sentence</th><td>9.7</td><td>10.1</td><td>9.9</td>
		      </tr>
		      <tr>
			<th colspan="4" class="text-center">#Tokens (MT versions)</th>
		      </tr>
		      <tr>
			<th scope="row">Total</th><td>28,745</td><td>27,510</td><td>56,255</td>
		      </tr>
		      <tr>
			<th scope="row">Total unique</th><td>3,698</td><td>3,141</td><td>-</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per dialogue</th><td>199.6</td><td>191.0</td><td>390.7</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per sentence</th><td>10.0</td><td>9.5</td><td>9.8</td>
		      </tr>
		      <tr>
			<th colspan="4" class="text-center">#Tokens (reference translations)</th>
		      </tr>
		      <tr>
			<th scope="row">Total</th><td>30,093</td><td>27,014</td><td>57,107</td>
		      </tr>
		      <tr>
			<th scope="row">Total unique</th><td>4,361</td><td>3,556</td><td>-</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per dialogue</th><td>209.0</td><td>187.6</td><td>396.6</td>
		      </tr>
		      <tr>
			<th scope="row">Mean per sentence</th><td>10.5</td><td>9.4</td><td>9.9</td>
		      </tr>
		    </tbody>
		  </table>
		  
		</div>
		</section><!--//doc-section-->
		
		<section id="dashboards" class="doc-section">
		<h3 class="section-subtitle"><a id="user-stats"></a>User statistics</h3>
		<div class="section-block">

		  <p>Some basic statistics concerning the 75 different participants:</p>

		  <table class="table table-hover table-sm ">
		    <thead class="thead-light">
		      <tr>
			<th></th><th>En</th><th>Fr</th><th>All</th>
		      </tr>
		      </thead>
		    <tbody>
		      <tr>
			<th scope="row">Total number</th><td>37</td><td>38</td><td>75</td>
		      </tr>
		      <tr>
			<th scope="row">&nbsp; &nbsp;#Researchers</th><td>7</td><td>17</td><td>24</td>
		      </tr>
		      <tr>
			<th scope="row">&nbsp; &nbsp;#Experience in NLP</th><td>6</td><td>14</td><td>20</td>
		      </tr>
		      <tr>
			<th scope="row">&nbsp; &nbsp;#Female/#Male</th><td>21 / 16</td><td>16 / 22</td><td>37 / 38</td>
		      </tr>
		      <tr>
			<th scope="row">Min. age</th><td>18-24</td><td>18-24</td><td>18-24</td>
		      </tr>
		      <tr>
			<th scope="row">Max. age</th><td>65-74</td><td>65-74</td><td>18-24</td>
		      </tr>
		      <tr>
			<th scope="row">Median age</th><td>55_64</td><td>25-34</td><td>35-44</td>
		      </tr>
		      <tr>
			<th scope="row">Modal age</th><td>55-64</td><td>25-34</td><td>25-34</td>
		      </tr>
		    </tbody>
		  </table>
		  
		</div>
		</section>
		
		</div><!--//content-inner-->
		</div><!--//doc-content-->
		<div class="doc-sidebar col-md-3 col-12 order-0 d-none d-md-flex">
		<div id="doc-nav" class="doc-nav">
		  <nav id="doc-menu" class="nav doc-menu flex-column sticky">
		  <a class="nav-link scrollto" href="#description">Description</a>
		  <nav class="doc-sub-menu nav flex-column">
		  <a class="nav-link scrollto" href="#mt-models">Machine translation models</a>
		  <a class="nav-link scrollto" href="#role-play">Role-play scenarios</a>
		  <a class="nav-link scrollto" href="#eval">Evaluation</a>
		  <nav class="doc-sub-menu nav flex-column">
		  <a class="nav-link scrollto" href="#human-refs">&nbsp;<i class="fas fa-play fa-xs"></i>&nbsp; Human reference translations</a>
		  <a class="nav-link scrollto" href="#user-eval">&nbsp;<i class="fas fa-play fa-xs"></i>&nbsp; Real-time user evaluation</a>
		  </nav>
		  </nav>
		  <a class="nav-link scrollto" href="#stats">Statistics</a>
		  <nav class="doc-sub-menu nav flex-column">
		  <a class="nav-link scrollto" href="#corpus-stats">Corpus stats</a>
		  <a class="nav-link scrollto" href="#user-stats">User stats</a>
		  </nav>
		  </nav><!--//doc-menu-->
		</div><!--//doc-nav-->
		</div><!--//doc-sidebar-->
		</div><!--//doc-body-->              
		</div><!--//container-->
		</div><!--//doc-wrapper-->
		
		
		
		</div><!--//page-wrapper-->
		
		<footer id="footer" class="footer text-center">
		<div class="container">
		  <!--/* This template is released under the Creative Commons Attribution 3.0 License. Please keep the attribution link below when using for your own project. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
		  <small class="copyright">Designed with <i class="fa fa-heart"></i> by <a href="https://themes.3rdwavemedia.com/" target="_blank">Xiaoying Riley</a> for developers</small>
		  
		</div><!--//container-->
		</footer><!--//footer-->
		
		
		<!-- Main Javascript -->          
		<script type="text/javascript" src="assets/plugins/jquery-3.3.1.min.js"></script>
		<script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>
		<script type="text/javascript" src="assets/plugins/prism/prism.js"></script>    
		<script type="text/javascript" src="assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script>  
		<script type="text/javascript" src="assets/plugins/lightbox/dist/ekko-lightbox.min.js"></script>      
		<script type="text/javascript" src="assets/plugins/stickyfill/dist/stickyfill.min.js"></script>                                                                  <script type="text/javascript" src="assets/js/main.js"></script>
		
</body>
</html> 
		
		